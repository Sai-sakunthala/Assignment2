{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-sakunthala/Assignment2/blob/main/Assignment_2_partA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "3JaznyWc1crF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anv2qAdBcOCG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as functional\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import pytorch_lightning as pl\n",
        "from torchvision import transforms, datasets\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8jXXTvRExa_"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"C:\\Users\\sai sakunthala\\Desktop\\deep learning\\A2\\nature_12K.zip\" -d 'C:\\Users\\sai sakunthala\\Desktop\\deep learning\\A2\\inaturalist_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o9ZSLpnGo35"
      },
      "outputs": [],
      "source": [
        "class CNN(pl.LightningModule):\n",
        "    def __init__(self, initial_in_channels=3, num_classes=10, num_conv_layers=5, num_filters=32, kernel_size=3, activation_fn=nn.ReLU,\n",
        "                 dense_neurons=256, learning_rate=1e-3, use_batchnorm=False, dropout_rate=0.3, filter_organization='same', data_augmentation = False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        layers_list = []\n",
        "        input_channels = initial_in_channels\n",
        "        current_filters = num_filters\n",
        "\n",
        "        for i in range(num_conv_layers):\n",
        "            output_channels = current_filters\n",
        "            layers_list.append(nn.Conv2d(input_channels, output_channels, kernel_size = kernel_size, padding = kernel_size//2))\n",
        "            if use_batchnorm:\n",
        "                layers_list.append(nn.BatchNorm2d(output_channels))\n",
        "            layers_list.append(activation_fn())\n",
        "            if dropout_rate == 0:\n",
        "                layers_list.append(nn.Dropout(dropout_rate))\n",
        "            layers_list.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            input_channels = output_channels\n",
        "            if filter_organization == 'double':\n",
        "                current_filters *= 2\n",
        "            elif filter_organization == 'half':\n",
        "                current_filters = max(4, current_filters // 2)\n",
        "\n",
        "        self.convolution_block = nn.Sequential(*layers_list)\n",
        "        self.fc1 = nn.LazyLinear(dense_neurons)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(dense_neurons) if use_batchnorm else None\n",
        "        self.activation_dense = activation_fn()\n",
        "        self.dropout_fc1 = nn.Dropout(dropout_rate) if dropout_rate == 0 else None\n",
        "        self.fc2 = nn.Linear(dense_neurons, num_classes)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolution_block(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        if self.hparams.use_batchnorm:\n",
        "            x = self.bn_fc1(x)\n",
        "        x = self.activation_dense(x)\n",
        "        if self.hparams.dropout_rate == 0:\n",
        "            x = self.dropout_fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = functional.cross_entropy(y_hat, y)\n",
        "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = functional.cross_entropy(y_hat, y)\n",
        "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrYTERxnBrFT"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'num_filters': {'values': [32, 64]},\n",
        "        'activation_fn': {'values': ['ReLU', 'SiLU', 'GELU', 'Mish']},\n",
        "        'filter_organization': {'values': ['same', 'double', 'half']},\n",
        "        'use_batchnorm': {'values': [True, False]},\n",
        "        'dropout_rate': {'values': [0, 0.2, 0.3]},\n",
        "        'dense_neurons': {'values': [128, 256, 512]},\n",
        "        'learning_rate': {'values': [1e-3]},\n",
        "        'batch_size': {'values': [64]},\n",
        "        'data_augmentation': {'values': [True, False]},\n",
        "        'kernel_size': {'values': [3, 5]},\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZCU3yJQFEbR"
      },
      "outputs": [],
      "source": [
        "def get_activation(name):\n",
        "    return {\n",
        "        \"ReLU\": nn.ReLU,\n",
        "        \"GELU\": nn.GELU,\n",
        "        \"SiLU\": nn.SiLU,\n",
        "        \"Mish\": nn.Mish\n",
        "    }[name]\n",
        "\n",
        "\n",
        "def train(config=None):\n",
        "    with wandb.init(config=config) as run:\n",
        "        random.seed(42)\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        config = wandb.config\n",
        "        run.name = f\"{config.activation_fn}_f{config.num_filters}_k{config.kernel_size}_{config.filter_organization}_bn{int(config.use_batchnorm)}_r{config.dropout_rate}_fc{config.dense_neurons}_aug{int(config.data_augmentation)}\"\n",
        "        run.save()\n",
        "\n",
        "        wandb_logger = WandbLogger(project=\"cnn-sweep\", log_model='all')\n",
        "\n",
        "        if config.get(\"data_augmentation\", False):\n",
        "            transform_list = [\n",
        "                transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(15),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                transforms.Resize((128, 128)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ]\n",
        "        else:\n",
        "            transform_list = [\n",
        "                transforms.Resize((128, 128)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ]\n",
        "\n",
        "        transform = transforms.Compose(transform_list)\n",
        "\n",
        "        data_dir = \"/content/inaturalist_data/inaturalist_12K/train\"\n",
        "\n",
        "        full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "        num_classes = len(full_dataset.classes)\n",
        "\n",
        "        class_to_indices = defaultdict(list)\n",
        "        for idx, (_, label) in enumerate(full_dataset.samples):\n",
        "            class_to_indices[label].append(idx)\n",
        "\n",
        "        train_indices = []\n",
        "        val_indices = []\n",
        "\n",
        "        for label, indices in class_to_indices.items():\n",
        "            random.shuffle(indices)\n",
        "            split = int(0.8 * len(indices))\n",
        "            train_indices.extend(indices[:split])\n",
        "            val_indices.extend(indices[split:])\n",
        "\n",
        "        random.shuffle(train_indices)\n",
        "\n",
        "        train_dataset = Subset(full_dataset, train_indices)\n",
        "        val_dataset = Subset(full_dataset, val_indices)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, config.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(val_dataset, config.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        class_names = full_dataset.classes\n",
        "\n",
        "        model = CNN(\n",
        "            initial_in_channels=3,\n",
        "            num_classes=num_classes,\n",
        "            num_conv_layers=5,\n",
        "            num_filters=config.num_filters,\n",
        "            kernel_size=config.kernel_size,\n",
        "            activation_fn=get_activation(config.activation_fn),\n",
        "            dense_neurons=config.dense_neurons,\n",
        "            learning_rate=config.learning_rate,\n",
        "            use_batchnorm=config.use_batchnorm,\n",
        "            dropout_rate=config.dropout_rate,\n",
        "            filter_organization=config.filter_organization,\n",
        "            data_augmentation=config.data_augmentation\n",
        "        )\n",
        "\n",
        "        callbacks = [\n",
        "            #pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
        "            pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1)\n",
        "        ]\n",
        "\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=5,\n",
        "            precision=16,\n",
        "            logger=wandb_logger,\n",
        "            accelerator=\"gpu\",   # Ensure it uses GPU\n",
        "            devices=1,\n",
        "            callbacks=callbacks,\n",
        "            gradient_clip_val=0.5\n",
        "        )\n",
        "        try:\n",
        "            trainer.fit(model, train_loader, val_loader)\n",
        "        finally:\n",
        "            wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"cnn-sweep-2\")\n",
        "wandb.agent(sweep_id, function=train, count=60)"
      ],
      "metadata": {
        "id": "mp31G6mW3sMb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}