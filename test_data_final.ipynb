{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1miIDp624rDouvotp25ceuhoafZ8XSyqr",
      "authorship_tag": "ABX9TyMPqFFCGYmrua6Ou6jSW8SN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-sakunthala/Assignment2/blob/main/test_data_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "a1e26PM0O5DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import wandb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_lightning as pl\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch import nn\n",
        "import torch.nn.functional as functional\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from collections import defaultdict\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "class CNN(pl.LightningModule):\n",
        "    def __init__(self, initial_in_channels=3, num_classes=10, num_conv_layers=5, num_filters=64, kernel_size=3, activation_fn=nn.SiLU,\n",
        "                 dense_neurons=256, learning_rate=1e-3, use_batchnorm=True, dropout_rate=0.3, filter_organization='same', data_augmentation = True):\n",
        "\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # initialize a list to save all convolution layers\n",
        "        layers_conv = []\n",
        "\n",
        "        #number of imput images channels which is 3 in our case\n",
        "        input_channels = initial_in_channels\n",
        "\n",
        "        #variable to track filters in current layer\n",
        "        current_filters = num_filters\n",
        "\n",
        "        #loop over number of convolution layers\n",
        "        for i in range(num_conv_layers):\n",
        "            #number of output channels needed\n",
        "            out_channels = current_filters\n",
        "\n",
        "            #convolution layer with padding\n",
        "            layers_conv.append(nn.Conv2d(input_channels, out_channels, kernel_size = kernel_size, padding = kernel_size//2))\n",
        "\n",
        "            #if batch normalization is specified use it\n",
        "            if use_batchnorm:\n",
        "                layers_conv.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "            #activation layer\n",
        "            layers_conv.append(activation_fn())\n",
        "\n",
        "            #dropout is added after activation layer\n",
        "            if dropout_rate == 0:\n",
        "                layers_conv.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "            #maxpool layer\n",
        "            layers_conv.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "            #update input channels\n",
        "            input_channels = out_channels\n",
        "\n",
        "            #update number of filters for following layers based on configuration\n",
        "            if filter_organization == 'double':\n",
        "                current_filters *= 2\n",
        "            elif filter_organization == 'half':\n",
        "                current_filters = max(4, current_filters // 2)\n",
        "\n",
        "        #add all layers as convolution block\n",
        "        self.conv_block = nn.Sequential(*layers_conv)\n",
        "\n",
        "        #dense layer\n",
        "        self.fc1 = nn.LazyLinear(dense_neurons)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(dense_neurons) if use_batchnorm else None\n",
        "        self.activation_dense = activation_fn()\n",
        "        self.dropout_fc1 = nn.Dropout(dropout_rate) if dropout_rate == 0 else None\n",
        "\n",
        "        #final classification layer\n",
        "        self.fc2 = nn.Linear(dense_neurons, num_classes)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        #forward propagation of network\n",
        "        x = self.conv_block(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        if self.hparams.use_batchnorm:\n",
        "            x = self.bn_fc1(x)\n",
        "        x = self.activation_dense(x)\n",
        "        if self.hparams.dropout_rate == 0:\n",
        "            x = self.dropout_fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        #training in batches\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = functional.cross_entropy(y_hat, y)\n",
        "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        #log metrics\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        #validation in batches\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = functional.cross_entropy(y_hat, y)\n",
        "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        #log metrics\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        #useful for testing the model later\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = functional.cross_entropy(y_hat, y)\n",
        "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        #log metrics\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_acc\", acc, prog_bar=True)\n",
        "        return {\"test_loss\": loss, \"test_acc\": acc}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        #adam optimizer with weightdecay\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay = 5e-5)\n",
        "\n",
        "        #learning rate scheduler\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "#Load best model from sweep\n",
        "api = wandb.Api()\n",
        "sweep_id = '1f9810oq'\n",
        "sweep_path = f\"sai-sakunthala-indian-institute-of-technology-madras/cnn-sweep/{sweep_id}\"\n",
        "sweep = api.sweep(sweep_path)\n",
        "best_run = max(sweep.runs, key=lambda r: r.summary.get('val_acc', 0))\n",
        "artifact = best_run.logged_artifacts()[0]\n",
        "artifact_dir = artifact.download()\n",
        "ckpt_path = os.path.join(artifact_dir, \"model.ckpt\")\n",
        "\n",
        "#Load the model\n",
        "best_model = CNN.load_from_checkpoint(ckpt_path)\n",
        "best_model.eval()\n",
        "\n",
        "#Test transform\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "#Load test set\n",
        "test_dir = \"/content/inaturalist_data/inaturalist_12K/val\"\n",
        "test_dataset = ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "class_names = test_dataset.classes\n",
        "\n",
        "#Evaluate test accuracy\n",
        "test_run = wandb.init(project=\"cnn-sweep\", name=\"final_test_evaluation\", job_type=\"evaluation\")\n",
        "test_trainer = pl.Trainer(accelerator = 'auto', logger=False)\n",
        "test_results = test_trainer.test(best_model, dataloaders=test_loader)\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "#Store per-class correct and total counts\n",
        "class_correct = defaultdict(int)\n",
        "class_total = defaultdict(int)\n",
        "\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.to(best_model.device), y.to(best_model.device)\n",
        "        outputs = best_model(x)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        for label, pred in zip(y, preds):\n",
        "            class_total[label.item()] += 1\n",
        "            if label == pred:\n",
        "                class_correct[label.item()] += 1"
      ],
      "metadata": {
        "id": "529EYoV4PJvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute accuracy per class\n",
        "class_wise_accuracy = {}\n",
        "for class_idx in range(len(class_names)):\n",
        "    correct = class_correct[class_idx]\n",
        "    total = class_total[class_idx]\n",
        "    acc = 100 * correct / total if total > 0 else 0.0\n",
        "    class_wise_accuracy[class_names[class_idx]] = acc\n",
        "\n",
        "#Log runs\n",
        "test_run.log({\"ðŸ“Š Class-wise Test Accuracy\": class_wise_accuracy})\n",
        "test_run.finish()\n",
        "\n",
        "wandb.init(project=\"cnn-sweep\", name=\"final_test_table\", job_type=\"evaluation\")\n",
        "\n",
        "#Create the table with columns for class names and accuracy values\n",
        "table = wandb.Table(columns=[\"Class\", \"Accuracy\"])\n",
        "\n",
        "#Add data from the class_wise_accuracy dictionary to the table\n",
        "for class_name, accuracy in class_wise_accuracy.items():\n",
        "    table.add_data(class_name, accuracy)\n",
        "\n",
        "#Log the table to wandb\n",
        "wandb.log({\"Class-wise Accuracy Table\": table})\n",
        "\n",
        "#Finish the wandb run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "GzLxaa6pR8Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2  #For adding borders\n",
        "\n",
        "#Target per class\n",
        "target_total_per_class = 3\n",
        "\n",
        "#Initialize wandb\n",
        "wandb.init(project=\"inatiralist_finetune\", name=\"final_test_images_2\", job_type=\"evaluation\")\n",
        "\n",
        "#Set model to evaluation mode\n",
        "best_model.eval()\n",
        "\n",
        "#Collect images per class (label-wise)\n",
        "samples_per_class = {i: [] for i in range(len(class_names))}\n",
        "\n",
        "#Function to add border (green if correct, red otherwise)\n",
        "def add_border_to_image(img, is_correct):\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    color = (0, 255, 0) if is_correct else (255, 0, 0)\n",
        "    thickness = 5\n",
        "    return cv2.copyMakeBorder(img, thickness, thickness, thickness, thickness, cv2.BORDER_CONSTANT, value=color)\n",
        "\n",
        "# Collect predictions and prepare images\n",
        "with torch.no_grad():\n",
        "    for idx in range(len(test_dataset)):\n",
        "        img, true_label = test_dataset[idx]\n",
        "        input_tensor = img.unsqueeze(0).to(best_model.device)\n",
        "        output = best_model(input_tensor)\n",
        "        pred_label = output.argmax(dim=1).item()\n",
        "\n",
        "        # De-normalize image\n",
        "        img_disp = img.permute(1, 2, 0).cpu().numpy()\n",
        "        img_disp = img_disp * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img_disp = np.clip(img_disp, 0, 1)\n",
        "\n",
        "        # Determine prediction correctness (for display only)\n",
        "        correct = pred_label == true_label\n",
        "        img_with_border = add_border_to_image(img_disp, correct)\n",
        "        caption = f\"True: {class_names[true_label]} | Pred: {class_names[pred_label]}\"\n",
        "        wandb_img = wandb.Image(img_with_border, caption=caption)\n",
        "\n",
        "        # Collect up to 3 samples per class\n",
        "        if len(samples_per_class[true_label]) < target_total_per_class:\n",
        "            samples_per_class[true_label].append(wandb_img)\n",
        "\n",
        "        # Exit once all classes are satisfied\n",
        "        if all(len(v) >= target_total_per_class for v in samples_per_class.values()):\n",
        "            break\n",
        "\n",
        "#flatten to a list\n",
        "wandb_imgs = [img for images in samples_per_class.values() for img in images]\n",
        "\n",
        "# Log to wandb\n",
        "wandb.log({\"Classwise Predictions Grid\": wandb_imgs})\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "Z1f5I1GFT1XF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}